{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c78b4e80-347e-4a44-951e-69579daaba70",
   "metadata": {},
   "source": [
    "# Employee Attrition Prediction System"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b781a0-d200-4ad5-a6e9-a1bccd8081ac",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Machine Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d033b82a-10cd-4dc3-b963-78583bf132ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf8cbff1bc4464185ed002779b9d8df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileUpload(value=(), accept='.csv', description='Upload CSV')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "import io\n",
    "\n",
    "# Create a file upload widget\n",
    "training_data_upload_widget = widgets.FileUpload(\n",
    "    accept='.csv',  # Restrict to .csv files\n",
    "    multiple=False,  # Allow only one file to be uploaded\n",
    "    description='Upload CSV',\n",
    "    layout=widgets.Layout(width='auto', height='auto')\n",
    ")\n",
    "\n",
    "# Display the file upload widget\n",
    "display(training_data_upload_widget)\n",
    "\n",
    "\n",
    "def process_uploaded_file(datatype):\n",
    "    if datatype == 'training':\n",
    "        upload_widget = training_data_upload_widget\n",
    "    elif datatype == 'prediction':\n",
    "        upload_widget = prediction_data_upload_widget\n",
    "        \n",
    "    if upload_widget.value:\n",
    "        # Extract the first (and only) item from the tuple\n",
    "        file_info = upload_widget.value[0]\n",
    "        \n",
    "        # Extract the file content from the file_info dictionary\n",
    "        content = file_info['content']\n",
    "        df = pd.read_csv(io.BytesIO(content))\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29119ad1-c013-4415-913f-cf5dde745ecc",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "\n",
    "# Probability threshold for classifying employee as attrition risk\n",
    "# Raising this number will increase precision but reduce recall\n",
    "# Lowering this number will reduce precision but increase recall\n",
    "# 0.3 results in the best balance between precision and recall (F1 score) in this model\n",
    "CLASSIFICATION_THRESHOLD = 0.3\n",
    "\n",
    "\n",
    "# Features to drop from dataset\n",
    "DROP_COLUMNS = ['Over18', 'EmployeeNumber', 'StandardHours', 'EmployeeCount']\n",
    "\n",
    "class AttritionModel:\n",
    "   \n",
    "    def __init__(self):\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.y_train = None\n",
    "        self.y_test = None\n",
    "        self.confusion_matrices = {}\n",
    "        self.preprocessor = None\n",
    "        self.models = self.initialize_models()\n",
    "\n",
    "    \n",
    "    # Initialize models with predefined hyperparameters chosen based on prior tuning\n",
    "    # This is based on hyperparamter tuning that was conducted using GridSearchCV\n",
    "    def initialize_models(self):\n",
    "        return {\n",
    "            'Logistic Regression': LogisticRegression(C=0.01, class_weight='balanced', max_iter=5000, penalty='l2', solver='liblinear', random_state=42),\n",
    "            'Gradient Boosting': GradientBoostingClassifier(learning_rate=0.2, max_depth=3, n_estimators=200, random_state=42),\n",
    "            'Random Forest': RandomForestClassifier(class_weight=None, max_depth=15, max_features=None, n_estimators=200, random_state=42),\n",
    "            'Neural Network': MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100), solver='lbfgs', random_state=42),\n",
    "            'Ensemble': VotingClassifier(estimators=[\n",
    "                ('lr', LogisticRegression(C=0.01, class_weight='balanced', max_iter=5000, penalty='l2', solver='liblinear', random_state=42)),\n",
    "                ('gb', GradientBoostingClassifier(learning_rate=0.2, max_depth=3, n_estimators=200, random_state=42)),\n",
    "                ('rf', RandomForestClassifier(class_weight=None, max_depth=15, max_features=None, n_estimators=200, random_state=42)),\n",
    "                ('nn', MLPClassifier(activation='logistic', hidden_layer_sizes=(100, 100), solver='lbfgs', random_state=42))],\n",
    "                voting='soft')\n",
    "        }\n",
    "\n",
    "    \n",
    "    def initialize_preprocessor(self, data):\n",
    "        if self.preprocessor:\n",
    "            return\n",
    "        else:\n",
    "            # Defining numerical and categorical columns\n",
    "            numerical_cols = self.X_train.select_dtypes(include=['int64', 'float64']).columns\n",
    "            categorical_cols = self.X_train.select_dtypes(include=['object']).columns\n",
    "    \n",
    "            # Creating preprocessing pipelines for both numeric and categorical data\n",
    "            self.preprocessor = ColumnTransformer(\n",
    "                transformers=[\n",
    "                    ('num', Pipeline(steps=[('scaler', StandardScaler())]), numerical_cols),\n",
    "                    ('cat', Pipeline(steps=[('onehot', OneHotEncoder(handle_unknown='ignore'))]), categorical_cols)\n",
    "                ],\n",
    "                remainder='passthrough'\n",
    "            )\n",
    "\n",
    "\n",
    "    def preprocess_training_data(self, data):\n",
    "        # Separating features and target variable and dropping non-relevant columns\n",
    "        drop_columns_copy = DROP_COLUMNS.copy()\n",
    "        drop_columns_copy.append('Attrition')\n",
    "        X = data.drop((drop_columns_copy), axis=1)\n",
    "        y = data['Attrition'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "        # Splitting data into training and testing sets\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "        self.initialize_preprocessor(self.X_train)\n",
    "        \n",
    "        # Fit the preprocessor with training data\n",
    "        self.preprocessor.fit(self.X_train)\n",
    "\n",
    "        # Transform the training and testing data\n",
    "        self.X_train = self.preprocessor.transform(self.X_train)\n",
    "        self.X_test = self.preprocessor.transform(self.X_test)\n",
    "\n",
    "    \n",
    "    def preprocess_prediction_data(self, data):\n",
    "        data = data.drop((DROP_COLUMNS), axis=1)\n",
    "        preprocessed_data = self.preprocessor.transform(data)\n",
    "        return preprocessed_data       \n",
    "\n",
    "           \n",
    "    def train_and_evaluate_model(self, name, model, print_metrics=False):\n",
    "        model.fit(self.X_train, self.y_train)\n",
    "        y_prob = model.predict_proba(self.X_test)[:, 1]\n",
    "        predictions = (y_prob >= CLASSIFICATION_THRESHOLD).astype(int)\n",
    "        \n",
    "        accuracy = accuracy_score(self.y_test, predictions)\n",
    "        precision = precision_score(self.y_test, predictions)\n",
    "        recall = recall_score(self.y_test, predictions)\n",
    "        f1 = f1_score(self.y_test, predictions)\n",
    "        roc_auc = roc_auc_score(self.y_test, y_prob)\n",
    "\n",
    "        if print_metrics:\n",
    "            print(f'{name} Model Evaluation:')\n",
    "            print(f'Accuracy: {accuracy:.4f}')\n",
    "            print(f'Precision: {precision:.4f}')\n",
    "            print(f'Recall: {recall:.4f}')\n",
    "            print(f'F1 Score: {f1:.4f}')\n",
    "            print(f'ROC AUC: {roc_auc:.4f}')\n",
    "\n",
    "        self.confusion_matrices[name] = confusion_matrix(self.y_test, predictions)        \n",
    "    \n",
    "    \n",
    "    # Evaluate each model on test data\n",
    "    def train_and_evaluate_all_models(self):\n",
    "        print('\\nTraining and Evaluating models...\\n')\n",
    "        for name, model in self.models.items():\n",
    "            self.train_and_evaluate_model(name, model, print_metrics=True)\n",
    "            print()\n",
    "\n",
    "        \n",
    "    def train_model(self):\n",
    "        data = process_uploaded_file(datatype='training')\n",
    "        # data = pd.read_csv('data/WA_Fn-UseC_-HR-Employee-Attrition.csv')\n",
    "        self.preprocess_training_data(data)\n",
    "        self.train_and_evaluate_all_models()\n",
    "\n",
    "    \n",
    "    def generate_predictions(self):\n",
    "        print('Generating Predictions...\\n')\n",
    "        prediction_data = process_uploaded_file(datatype='prediction')\n",
    "        employee_numbers = prediction_data['EmployeeNumber']\n",
    "        preprocessed_data = self.preprocess_prediction_data(prediction_data)\n",
    "        model = self.models['Ensemble']\n",
    "        y_prob = model.predict_proba(preprocessed_data)[:, 1]\n",
    "        predictions = (y_prob >= CLASSIFICATION_THRESHOLD).astype(int)\n",
    "        predictions = ['Yes' if pred == 1 else 'No' for pred in predictions]\n",
    "        for emp_num, pred in zip(employee_numbers, predictions):\n",
    "            print(f'Employee Number: {emp_num}, Attrition Risk: {pred}')       \n",
    "        \n",
    "\n",
    "# Instantiate new AttritionModel object\n",
    "attrition_model = AttritionModel()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fdf4822-9385-499c-90d6-be0d13fe19c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8401514-e47b-4dbd-921e-4ba96a2d457a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Create a button widget for running the model\n",
    "train_model_button = widgets.Button(\n",
    "    description=\"Train Model\", \n",
    "    disabled=True,\n",
    "    layout=widgets.Layout(width='auto', height='auto')\n",
    ")\n",
    "\n",
    "\n",
    "# Output widget for the model\n",
    "training_output = widgets.Output()\n",
    "\n",
    "\n",
    "# Callback function for the run model button\n",
    "def on_train_model_button_clicked(b):\n",
    "    with training_output:\n",
    "        clear_output(wait=True)\n",
    "        attrition_model.train_model() \n",
    "        print(\"\\n\\nModel training and evaluation completed.\")\n",
    "    prediction_data_upload_widget.disabled=False\n",
    "\n",
    "\n",
    "# Link the button to the callback function\n",
    "train_model_button.on_click(on_train_model_button_clicked)\n",
    "# Display the button and the output widget for the model\n",
    "display(train_model_button, training_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72a5699-82ca-49ad-be7e-86ca1220d038",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff847b-4749-495a-9eb6-5139a5552784",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "\n",
    "def generate_visualizations():\n",
    "    data = process_uploaded_file(datatype='training')\n",
    "    \n",
    "    # Correlation Graph\n",
    "    # Preparing the data for the correlation graph\n",
    "    data_filtered = data.drop(columns=['EmployeeNumber', 'StandardHours', 'EmployeeCount'])\n",
    "    data_filtered['Attrition'] = data_filtered['Attrition'].map({'Yes': 1, 'No': 0})\n",
    "    data_filtered['BusinessTravel'] = data_filtered['BusinessTravel'].map({'Non_Travel': 1, 'Travel_Rarely': 2, 'Travel_Frequently': 3})\n",
    "    attrition_correlations = data_filtered.corr(numeric_only=True)['Attrition'].sort_values()\n",
    "\n",
    "    \n",
    "    # Excluding the correlation of 'Attrition' with itself\n",
    "    attrition_correlations = attrition_correlations[attrition_correlations.index != 'Attrition']\n",
    "    \n",
    "    plt.figure(figsize=(12, 12))\n",
    "    sns.barplot(x=attrition_correlations.index, y=attrition_correlations.values, hue=attrition_correlations.index, palette='vlag', legend=False)\n",
    "    plt.title('Correlation of Features with Attrition')\n",
    "    plt.ylabel('Correlation Coefficient with Attrition')\n",
    "    plt.xlabel('Features')\n",
    "    plt.xticks(rotation=90)  # Rotate x-axis labels for better visibility\n",
    "    plt.show()\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    # Income Box and Whisker Graph\n",
    "    plt.figure(figsize=(12, 12))\n",
    "    sns.boxplot(x='JobRole', y='MonthlyIncome', hue='Attrition', data=data)\n",
    "    plt.title('Monthly Income Distribution by Job Role and Attrition Status')\n",
    "    plt.xlabel('Job Role')\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel('Monthly Income')\n",
    "    plt.legend(title='Attrition')\n",
    "    plt.show()\n",
    "    print()\n",
    "    \n",
    "    \n",
    "    # Confusion Matrix\n",
    "    def plot_confusion_matrix(cm, model_name):\n",
    "        plt.figure(figsize=(12, 12))\n",
    "        class_labels = ['No', 'Yes']\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels, cbar=False)\n",
    "        plt.title(f'Confusion Matrix for {model_name} Model')\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    #plot_confusion_matrix(attrition_model.confusion_matrices['Ensemble'], 'Ensemble')\n",
    "    for name, cm in attrition_model.confusion_matrices.items():\n",
    "        if name == 'Ensemble':  # Only create confusion matrix for Ensemble model\n",
    "            plot_confusion_matrix(cm, name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ae72f1-dee5-4d2c-88b6-7938b583d9d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a button widget for generating visualizations\n",
    "visualize_button = widgets.Button(\n",
    "    description=\"Generate Visualizations\", \n",
    "    disabled=True,\n",
    "    layout=widgets.Layout(width='auto', height='auto')\n",
    ")\n",
    "\n",
    "# Output widget for visualizations\n",
    "visualization_output = widgets.Output()\n",
    "\n",
    "# Callback function for the visualization button\n",
    "def on_visualize_button_clicked(b):\n",
    "    with visualization_output:\n",
    "        clear_output(wait=True)\n",
    "        generate_visualizations()\n",
    "\n",
    "\n",
    "# Link the button to the callback function\n",
    "visualize_button.on_click(on_visualize_button_clicked)\n",
    "# Display the button and the output widget for visualizations\n",
    "display(visualize_button, visualization_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffa2dc6-578b-487f-a279-3573ac0a4472",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724b4762-8f8c-4e28-9f0d-c26ed2f2565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a file upload widget\n",
    "prediction_data_upload_widget = widgets.FileUpload(\n",
    "    accept='.csv',  # Restrict to .csv files\n",
    "    multiple=False,  # Allow only one file to be uploaded\n",
    "    description='Upload CSV',\n",
    "    disabled=True,\n",
    "    layout=widgets.Layout(width='auto', height='auto')\n",
    ")\n",
    "\n",
    "# Display the file upload widget\n",
    "display(prediction_data_upload_widget)\n",
    "\n",
    "\n",
    "# Create a button widget for running the predictions\n",
    "generate_predictions_button = widgets.Button(\n",
    "    description=\"Generate Predictions\", \n",
    "    disabled=True,\n",
    "    layout=widgets.Layout(width='auto', height='auto')\n",
    ")\n",
    "\n",
    "\n",
    "# Output widget for the model\n",
    "predictions_output = widgets.Output()\n",
    "\n",
    "\n",
    "# Callback function for the run prediction button\n",
    "def on_generate_predictions_button_clicked(b):\n",
    "    with predictions_output:\n",
    "        clear_output(wait=True)\n",
    "        attrition_model.generate_predictions() \n",
    "\n",
    "\n",
    "# Link the button to the callback function\n",
    "generate_predictions_button.on_click(on_generate_predictions_button_clicked)\n",
    "# Display the button and the output widget for the model\n",
    "display(generate_predictions_button, predictions_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b960e1f-600c-4e6c-9217-951dcae0cf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to enable buttons if a file is uploaded\n",
    "def enable_buttons(change):\n",
    "    if training_data_upload_widget.value:\n",
    "        train_model_button.disabled = False\n",
    "        visualize_button.disabled = False\n",
    "    else:\n",
    "        train_model_button.disabled = True\n",
    "        visualize_button.disabled = True\n",
    "    if prediction_data_upload_widget.value:\n",
    "        generate_predictions_button.disabled = False\n",
    "    else:\n",
    "        generate_predictions_button.disabled = True\n",
    "\n",
    "\n",
    "# Attach the observer function to the file upload widget\n",
    "training_data_upload_widget.observe(enable_buttons, names='value')\n",
    "prediction_data_upload_widget.observe(enable_buttons, names='value')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
